episode,timestep,reward

update_timestep = max_ep_len * 4  # update policy every n timesteps
# log_freq = max(update_timestep, log_freq)  # make sure log_freq >= update_timestep
K_epochs = 120  # update policy for K epochs in one PPO update

eps_clip = 0.2  # clip parameter for PPO
gamma = 0.99  # discount factor

lr_actor = 0.0003  # learning rate for actor network
lr_critic = 0.001  # learning rate for critic network

buffer_size = 10000

random_seed = 0  # set random seed if required (0 = no random seed)
#####################################################

print("training environment name : " + env_name)

# env = gym.make(env_name)
trace_path = "trace/sweep.npy"
num_vehicles = 5  # number of vehicles in the environment
stage = 2
env = SimEnv(trace_path, num_vehicles=num_vehicles, stage=stage)

2,8000,[-1070.1119  2934.9048 -2399.7982 -4598.7725   455.3225]
4,16000,[ 2390.1999 -2661.7155  5868.3222  -252.3868 -4272.7835]
7,24000,[ 3071.0708 -1768.5235 -1384.1203 -1290.812  -2965.4065]
10,32000,[ 2712.6224 -1447.4044  3655.7717  1372.8323 -1900.9562]
12,40000,[-2123.2453  7060.9686  4220.6201  -287.2772  -780.4981]
14,48000,[ 2340.8945     8.3746 -1623.4803  6041.0049  1378.729 ]
16,56000,[6394.5895 -811.2845 3181.9292 5616.6752 4170.6296]
18,64000,[2710.776  3997.3203 1610.3003 -275.4079   63.4782]
21,72000,[2818.5331 1641.559  2304.0468 2533.501  3626.8864]
23,80000,[ 3935.23    1946.7037  3876.0223  2463.1027 -4086.3366]
25,88000,[1015.3282 1836.3586 2727.6979 1765.9872 -123.7136]
27,96000,[2462.5839 2773.87    818.9484 1705.1619 2574.0904]
30,104000,[   65.8621 -1539.5254   351.7159  -740.0328  1577.3005]
32,112000,[ 1886.7254 -1023.5918  2277.9514 -4796.2841 -2680.0283]
34,120000,[4249.6685 1720.8228  502.7038 1157.0634   84.3206]
37,128000,[-1474.9013   232.9317  1344.4585  -863.641   4987.1123]
39,136000,[ -606.183  -3300.7245  2121.5042  -396.2749  1644.4526]
41,144000,[ -358.829   2114.8856 -1221.835   2746.8721  2632.6442]
43,152000,[ 720.9551 5790.5134 2814.5145 2783.658  -365.0492]
46,160000,[   -8.1604 -2189.9139   -58.9859   270.3811  3046.4978]
48,168000,[-1680.8189  1494.9239 -3765.7426 -1083.6634  3583.108 ]
51,176000,[ 2117.4898  1526.2967  1633.1824  2494.1735 -4386.7375]
